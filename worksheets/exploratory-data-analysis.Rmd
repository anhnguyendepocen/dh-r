---
title: "Exploratory data analysis"
author: "Lincoln Mullen"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aims of the worksheet

Exploratory data analysis is the process of looking through a dataset to see what can be learned from it. At a minimum this entails looking at the way the data is structured and organized to figure out what kinds of information it has, as well as to identify potential gaps and errors in the data. An exploratory data analysis will also compute summary statistics on the data and make plots of relationships between the variables. Depending on the state of the data, it may also have to reshape or clean up the data. And finally, an exploratory data analysis may make use of more advanced techniques, such as creating statistical models of the data, clustering the data, reducing dimensionality through principal components analysis, or the like. While there are a number of common techniques, the actual approach taken will depend greatly on the actual dataset that you are working with. Over time you will develop a checklist of techniques that you use. But a good rule of thumb is to start with the simplest techniques, then build up in complexity as it proves itself to be necessary.

You will find these chapters or books on exploratory data analysis to be helpful: Arnold and Tilton's *Humanities Data in R*, ch. 3--5; Kaplan's *Data Computing*, ch. 14; and Roger Peng's *Exploratory Data Analysis with R*.

The aim of this worksheet is to introduce a few techniques for exploratory data analysis on the Methodists dataset, then introduce a new dataset on which you will practice. But don't forget the techniques taught in the worksheets on plotting (especially scatter plots and histograms) and in data manipulation.

## Loading and cleaning data

We will begin by loading the Methodist data and creating a column with total members.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(historydata)
methodists <- read_csv("http://lincolnmullen.com/projects/worksheets/data/methodists.csv")

# Create a new column with total number of members in a church
methodists <- methodists %>% 
  rowwise() %>% 
  mutate(members_indian = as.integer(members_indian),
         members_total = sum(members_general, members_white, members_colored, 
                             members_indian, na.rm = TRUE)) %>% 
  ungroup() %>% 
  select(-url)
```

Let's also write a function that figures out the decade from the year, and add the decade as a column to the data frame.

```{r}
decade <- function(x) {
  trunc(x / 10) * 10
}
# To show that it works
decade(1795:1805)

methodists <- methodists %>% 
  mutate(decade = decade(minutes_year))
```

And we will reshape the data into a different data frame to create a tidy version.

```{r}
methodists_tidy <- methodists %>% 
  gather(type_of_member, number_of_members, starts_with("members_"))
```

## Some techniques of exploratory data analysis

### Summary statistics

Using dplyr's `count()` function, along with summary statistics using `group_by()` and `summarize()` along with `mean()`, `median()` and the like can give you a quick sense of what is contained in the dataset.

The `summary()` function can also be quite useful. It can be used on data frames or vectors (as well as other objects).

```{r}
summary(methodists)
summary(methodists$members_total)
```

### Measures of density and distribution

Summary statistics like the mean, median, and quartile are useful for getting a sense of a variable's central tendencies, but they are less useful for getting a sense of the distribution of values in a variable. One very useful technique is to see how the values are distributed.^[Note that the term [distribution](https://en.wikipedia.org/wiki/Probability_distribution) has a technical meaning in statistics, though we are using it more colloquially here.]

Here we use the `geom_density()` geometry in ggplot2 to show the density distribution of values. Here we are figuring out the density distribution for the `members_total` value. The value on the y-axis may not be intuitively obvious. It is the proportion of the values in the dataset that have the value on the x-axis. So, in the 1770s about 0.0015 (0.15%) of churches had a membership of about 250. The total area under the density curve will be 1.

```{r}
ggplot(methodists, aes(x = members_total, fill = as.factor(decade))) +
  geom_density() +
  facet_wrap(~decade) +
  ggtitle("Distribution of the total size of congregations by decade") +
  scale_x_continuous(breaks = seq(0, 1500, 250), limits = c(0, 1500)) +
  guides(fill = FALSE) +
  ggtitle("Density plots comparing sizes of circuits by decade")
```

Another way to get a sense of the distribution of values is to use a boxplot. A boxplot show the distances between the quartiles (the box), values extending beyond the quartiles (the whiskers), plus outliers (the dots). (See `?geom_boxplot` for the full details.) Here we compare the distribution in the number of white and black members by decade.

```{r}
methodists_tidy %>% 
  filter(minutes_year >= 1802,
         type_of_member %in% c("members_colored", "members_white")) %>% 
ggplot(aes(x = type_of_member, y = number_of_members)) +
  geom_boxplot(outlier.color = "gray") +
  ylim(0, 1000) + facet_wrap(~ decade, ncol = 2) +
  ggtitle("Boxplots comparing white and black membership by decade")
```

Yet another way to get a sense of the distribution of a single variable is to use a histogram, which puts values into bins, then counts how many values fall into each of those bins. In this example, we count how many circuits fall into each bin, with each bin having a width of 100 members.

```{r}
methodists %>% 
  filter(minutes_year == 1825) %>% 
  ggplot(aes(x = members_total)) +
  geom_histogram(binwidth = 100) +
  xlim(0, 2000) +
  ggtitle("Histogram of the number of members in a circuit in 1825")
```

### Scatter plots and smoothing

The techniques above for showing the distribution work for a single variable. Often we want to know the relationship between two variables. A scatter plot is often the easiest way to get a sense of what is in two variables. Here we create a scatterplot of the relationship between white and black members by decade. It can be difficult to understand the relationship between the two variables, especially in a case like this where the points are overplotted and the values are widely dispersed. By using `geom_smooth()` we can fit a modeling function to the data. (See `?geom_smooth` and especially the `method =` parameter for the kinds of models you can use.) These models try to capture the relationship between the $x$ variable and the $y$ variable (the colored line), along with the uncertainty (the gray band around the line). In this case the line show the typical relationship between the number of white and black members.

```{r}
methodists %>% 
  filter(decade >= 1790, decade <= 1820) %>% 
ggplot(aes(members_white, members_colored)) +
  facet_wrap(~ decade) +
  geom_point(alpha = 0.1, shape = 1) +
  xlim(0, 1000) + ylim(0, 1000) +
  geom_smooth()
```

```{r, include=FALSE, eval=FALSE}
library(stringr)
set.seed(8232)
methodists_for_clustering <- methodists %>% 
  filter(minutes_year == 1829) %>% 
  select(conference, district, meeting, starts_with("members_"), -members_general) %>% 
  mutate(label = str_sub(meeting, 1, 12)) %>% 
  sample_n(50)

methodists_clust <- methodists_for_clustering %>% 
  dist() %>% 
  hclust() 

plot(methodists_clust, labels = methodists_for_clustering$label, hang = -1)


methodists_for_clustering$cluster <- cutree(methodists_clust, k = 4)

methodists_for_clustering %>% 
  group_by(cluster) %>% 
  summarize(n = n(),
            mean_total = mean(members_total, na.rm = TRUE),
            mean_black = mean(members_colored, na.rm = TRUE),
            mean_white = mean(members_white, na.rm = TRUE)) %>% 
  mutate(percent_black = mean_black / (mean_white + mean_black)) %>% 
  arrange(desc(percent_black))
```

```{r, include=FALSE, eval=FALSE}
library(fpc)
methodists_for_kmeans <- methodists_for_clustering %>% 
  select(starts_with("members_")) 
methodists_kmeans <- kmeans(methodists_for_kmeans, centers = 4)

plotcluster(methodists_for_kmeans, methodists_kmeans$cluster)
```


## Practice exploratory data analysis: A New Nation Votes 

For practice with exploratory data analysis, we will use the *A New Nation Votes* dataset. This is a dataset which contains election returns in the early American republic, from 1787 to 1825. You should see the [project webpage](http://elections.lib.tufts.edu/) and read about the dataset to find out what is in it and how it was collected. You may also wish to browse the online version of the database. Then you should [download the data itself](http://dl.tufts.edu/election_datasets).
 
Here is some code you can use to download all the data and load it in as a data frame. 

```{r, eval = FALSE}
library(readr)
url <- "http://dl.tufts.edu/file_assets/generic/tufts:MS115.003.001.00001/0"
if (!file.exists("all-votes.tsv")) {
  download.file(url, "nnv-all-votes.zip")
  unzip("nnv-all-votes.zip", files = "all-votes.tsv")
}
nnv <- read_tsv("all-votes.tsv")
```

In a separate Rmd file, create a report on the data. The report should be broken into two parts. The first part should be an exploration of the dataset where you examine what is in the data and explain (briefly) what you are trying to figure out and what you are seeing. Answer these kinds of questions, using plots if you need to. What kinds of elections were there? How many of each kind of election?  How many candidates and how often do they appear? Which parties? What does each row in the dataset represent? Which years are in the dataset, and how many elections are there in each year? Which states are represented?

The second part should isolate some useful subset of the data, from which you will create plots and summary statistics in the service of a historical argument. For instance, you might compare state or national politics, or compare two political parties, or follow some candidates. You might find [this blog post](http://lincolnmullen.com/blog/exploring-massachusetts-gubernatorial-elections/) helpful.

Your plots can be exploratory, meaning that they need not be perfect and ready for publication. But they should be *legible*. Adjust properties and filter the data as necessary to make them legible. And be sure to use labels and explain what you are seeing in prose.
